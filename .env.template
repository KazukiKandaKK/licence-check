# API Keys for LLM services
# Copy this file to .env and fill in your actual API keys

# ========== Cloud API Configuration ==========
# OpenAI API Key
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key  
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# ========== Local LLM Configuration ==========
# Set to 'true' to use local LLMs instead of cloud APIs
USE_LOCAL_LLM=false

# Ollama configuration (when using local LLMs)
OLLAMA_BASE_URL=http://localhost:11434

# Local models to alternate between (make sure they're installed in Ollama)
LOCAL_MODEL_1=codellama:7b
LOCAL_MODEL_2=deepseek-coder:6.7b

# Alternative model options:
# - llama2:7b
# - mistral:7b  
# - codellama:13b
# - deepseek-coder:33b